{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datas/wine.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4     5     6       7     8     9    10  11  12\n",
       "0   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1\n",
       "1   7.8  0.88  0.00  2.6  0.098  25.0  67.0  0.9968  3.20  0.68  9.8   5   1\n",
       "2   7.8  0.76  0.04  2.3  0.092  15.0  54.0  0.9970  3.26  0.65  9.8   5   1\n",
       "3  11.2  0.28  0.56  1.9  0.075  17.0  60.0  0.9980  3.16  0.58  9.8   6   1\n",
       "4   7.4  0.70  0.00  1.9  0.076  11.0  34.0  0.9978  3.51  0.56  9.4   5   1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.2457 - loss: 11.2014 - val_accuracy: 0.2285 - val_loss: 5.7345\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2486 - loss: 4.2920 - val_accuracy: 0.3962 - val_loss: 0.8277\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6760 - loss: 0.5563 - val_accuracy: 0.7815 - val_loss: 0.3843\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7646 - loss: 0.4389 - val_accuracy: 0.7969 - val_loss: 0.4131\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8082 - loss: 0.4185 - val_accuracy: 0.8754 - val_loss: 0.3327\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8771 - loss: 0.3127 - val_accuracy: 0.9192 - val_loss: 0.2662\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9164 - loss: 0.2741 - val_accuracy: 0.9192 - val_loss: 0.2738\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9239 - loss: 0.2595 - val_accuracy: 0.9231 - val_loss: 0.2475\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9291 - loss: 0.2288 - val_accuracy: 0.9269 - val_loss: 0.2371\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9203 - loss: 0.2435 - val_accuracy: 0.9277 - val_loss: 0.2282\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9304 - loss: 0.2199 - val_accuracy: 0.9269 - val_loss: 0.2203\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9330 - loss: 0.2051 - val_accuracy: 0.9292 - val_loss: 0.2133\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9332 - loss: 0.2016 - val_accuracy: 0.9323 - val_loss: 0.2070\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9345 - loss: 0.1977 - val_accuracy: 0.9315 - val_loss: 0.2040\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9402 - loss: 0.1931 - val_accuracy: 0.9331 - val_loss: 0.2009\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9390 - loss: 0.1893 - val_accuracy: 0.9338 - val_loss: 0.1989\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9395 - loss: 0.1902 - val_accuracy: 0.9338 - val_loss: 0.1971\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9424 - loss: 0.1775 - val_accuracy: 0.9331 - val_loss: 0.1962\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9339 - loss: 0.1940 - val_accuracy: 0.9338 - val_loss: 0.1950\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9386 - loss: 0.1835 - val_accuracy: 0.9354 - val_loss: 0.1931\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9402 - loss: 0.1770 - val_accuracy: 0.9354 - val_loss: 0.1928\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9418 - loss: 0.1783 - val_accuracy: 0.9354 - val_loss: 0.1917\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9393 - loss: 0.1875 - val_accuracy: 0.9362 - val_loss: 0.1906\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9412 - loss: 0.1818 - val_accuracy: 0.9385 - val_loss: 0.1893\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9401 - loss: 0.1767 - val_accuracy: 0.9362 - val_loss: 0.1892\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9447 - loss: 0.1708 - val_accuracy: 0.9369 - val_loss: 0.1872\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9460 - loss: 0.1615 - val_accuracy: 0.9369 - val_loss: 0.1844\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9431 - loss: 0.1773 - val_accuracy: 0.9362 - val_loss: 0.1828\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9383 - loss: 0.1792 - val_accuracy: 0.9354 - val_loss: 0.1816\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9383 - loss: 0.1766 - val_accuracy: 0.9354 - val_loss: 0.1812\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9477 - loss: 0.1645 - val_accuracy: 0.9354 - val_loss: 0.1796\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9403 - loss: 0.1785 - val_accuracy: 0.9354 - val_loss: 0.1785\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9477 - loss: 0.1649 - val_accuracy: 0.9362 - val_loss: 0.1778\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9406 - loss: 0.1708 - val_accuracy: 0.9362 - val_loss: 0.1764\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9395 - loss: 0.1693 - val_accuracy: 0.9369 - val_loss: 0.1744\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9445 - loss: 0.1688 - val_accuracy: 0.9377 - val_loss: 0.1730\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9464 - loss: 0.1552 - val_accuracy: 0.9385 - val_loss: 0.1708\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9469 - loss: 0.1656 - val_accuracy: 0.9369 - val_loss: 0.1701\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9464 - loss: 0.1599 - val_accuracy: 0.9385 - val_loss: 0.1673\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9402 - loss: 0.1713 - val_accuracy: 0.9392 - val_loss: 0.1661\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9454 - loss: 0.1544 - val_accuracy: 0.9385 - val_loss: 0.1640\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9482 - loss: 0.1459 - val_accuracy: 0.9431 - val_loss: 0.1628\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9449 - loss: 0.1547 - val_accuracy: 0.9408 - val_loss: 0.1602\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.1578 - val_accuracy: 0.9415 - val_loss: 0.1585\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9468 - loss: 0.1484 - val_accuracy: 0.9431 - val_loss: 0.1571\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9456 - loss: 0.1527 - val_accuracy: 0.9423 - val_loss: 0.1550\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9476 - loss: 0.1468 - val_accuracy: 0.9446 - val_loss: 0.1541\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9452 - loss: 0.1481 - val_accuracy: 0.9446 - val_loss: 0.1529\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9423 - loss: 0.1546 - val_accuracy: 0.9446 - val_loss: 0.1503\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9443 - loss: 0.1449 - val_accuracy: 0.9454 - val_loss: 0.1495\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25) # 0.8 x 0.25 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.9594 - loss: 0.1127\n",
      "Test accuracy: 0.949999988079071\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('./datas/wine.csv', header=None)\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    " shuffle=True)\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./datas/model/all/01-0.7592.keras\n",
      "\n",
      "Epoch 2: saving model to ./datas/model/all/02-0.8238.keras\n",
      "\n",
      "Epoch 3: saving model to ./datas/model/all/03-0.8038.keras\n",
      "\n",
      "Epoch 4: saving model to ./datas/model/all/04-0.8300.keras\n",
      "\n",
      "Epoch 5: saving model to ./datas/model/all/05-0.8631.keras\n",
      "\n",
      "Epoch 6: saving model to ./datas/model/all/06-0.8938.keras\n",
      "\n",
      "Epoch 7: saving model to ./datas/model/all/07-0.9123.keras\n",
      "\n",
      "Epoch 8: saving model to ./datas/model/all/08-0.9177.keras\n",
      "\n",
      "Epoch 9: saving model to ./datas/model/all/09-0.9200.keras\n",
      "\n",
      "Epoch 10: saving model to ./datas/model/all/10-0.9200.keras\n",
      "\n",
      "Epoch 11: saving model to ./datas/model/all/11-0.9262.keras\n",
      "\n",
      "Epoch 12: saving model to ./datas/model/all/12-0.9285.keras\n",
      "\n",
      "Epoch 13: saving model to ./datas/model/all/13-0.9300.keras\n",
      "\n",
      "Epoch 14: saving model to ./datas/model/all/14-0.9300.keras\n",
      "\n",
      "Epoch 15: saving model to ./datas/model/all/15-0.9323.keras\n",
      "\n",
      "Epoch 16: saving model to ./datas/model/all/16-0.9315.keras\n",
      "\n",
      "Epoch 17: saving model to ./datas/model/all/17-0.9315.keras\n",
      "\n",
      "Epoch 18: saving model to ./datas/model/all/18-0.9323.keras\n",
      "\n",
      "Epoch 19: saving model to ./datas/model/all/19-0.9323.keras\n",
      "\n",
      "Epoch 20: saving model to ./datas/model/all/20-0.9315.keras\n",
      "\n",
      "Epoch 21: saving model to ./datas/model/all/21-0.9338.keras\n",
      "\n",
      "Epoch 22: saving model to ./datas/model/all/22-0.9323.keras\n",
      "\n",
      "Epoch 23: saving model to ./datas/model/all/23-0.9323.keras\n",
      "\n",
      "Epoch 24: saving model to ./datas/model/all/24-0.9331.keras\n",
      "\n",
      "Epoch 25: saving model to ./datas/model/all/25-0.9331.keras\n",
      "\n",
      "Epoch 26: saving model to ./datas/model/all/26-0.9338.keras\n",
      "\n",
      "Epoch 27: saving model to ./datas/model/all/27-0.9338.keras\n",
      "\n",
      "Epoch 28: saving model to ./datas/model/all/28-0.9362.keras\n",
      "\n",
      "Epoch 29: saving model to ./datas/model/all/29-0.9346.keras\n",
      "\n",
      "Epoch 30: saving model to ./datas/model/all/30-0.9354.keras\n",
      "\n",
      "Epoch 31: saving model to ./datas/model/all/31-0.9354.keras\n",
      "\n",
      "Epoch 32: saving model to ./datas/model/all/32-0.9338.keras\n",
      "\n",
      "Epoch 33: saving model to ./datas/model/all/33-0.9338.keras\n",
      "\n",
      "Epoch 34: saving model to ./datas/model/all/34-0.9346.keras\n",
      "\n",
      "Epoch 35: saving model to ./datas/model/all/35-0.9362.keras\n",
      "\n",
      "Epoch 36: saving model to ./datas/model/all/36-0.9362.keras\n",
      "\n",
      "Epoch 37: saving model to ./datas/model/all/37-0.9369.keras\n",
      "\n",
      "Epoch 38: saving model to ./datas/model/all/38-0.9369.keras\n",
      "\n",
      "Epoch 39: saving model to ./datas/model/all/39-0.9377.keras\n",
      "\n",
      "Epoch 40: saving model to ./datas/model/all/40-0.9385.keras\n",
      "\n",
      "Epoch 41: saving model to ./datas/model/all/41-0.9385.keras\n",
      "\n",
      "Epoch 42: saving model to ./datas/model/all/42-0.9392.keras\n",
      "\n",
      "Epoch 43: saving model to ./datas/model/all/43-0.9415.keras\n",
      "\n",
      "Epoch 44: saving model to ./datas/model/all/44-0.9415.keras\n",
      "\n",
      "Epoch 45: saving model to ./datas/model/all/45-0.9415.keras\n",
      "\n",
      "Epoch 46: saving model to ./datas/model/all/46-0.9415.keras\n",
      "\n",
      "Epoch 47: saving model to ./datas/model/all/47-0.9423.keras\n",
      "\n",
      "Epoch 48: saving model to ./datas/model/all/48-0.9415.keras\n",
      "\n",
      "Epoch 49: saving model to ./datas/model/all/49-0.9415.keras\n",
      "\n",
      "Epoch 50: saving model to ./datas/model/all/50-0.9423.keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "modelpath=\"./datas/model/all/{epoch:02d}-{val_accuracy:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0,\n",
    " callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9515 - loss: 0.1345 \n",
      "Test accuracy: 0.9461538195610046\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9746 - loss: 0.0737 - val_accuracy: 0.9723 - val_loss: 0.1006\n",
      "Epoch 100/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9820 - loss: 0.0541 - val_accuracy: 0.9777 - val_loss: 0.0876\n",
      "Epoch 150/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9843 - loss: 0.0489 - val_accuracy: 0.9838 - val_loss: 0.0831\n",
      "Epoch 200/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9843 - loss: 0.0447 - val_accuracy: 0.9869 - val_loss: 0.0809\n",
      "Epoch 250/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9859 - loss: 0.0419 - val_accuracy: 0.9854 - val_loss: 0.0822\n",
      "Epoch 300/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9877 - loss: 0.0434 - val_accuracy: 0.9900 - val_loss: 0.0833\n",
      "Epoch 350/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9887 - loss: 0.0375 - val_accuracy: 0.9892 - val_loss: 0.0853\n",
      "Epoch 400/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9902 - loss: 0.0362 - val_accuracy: 0.9877 - val_loss: 0.0916\n",
      "Epoch 450/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9902 - loss: 0.0356 - val_accuracy: 0.9885 - val_loss: 0.0950\n",
      "Epoch 500/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9882 - loss: 0.0388 - val_accuracy: 0.9862 - val_loss: 0.0984\n",
      "Epoch 550/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9895 - loss: 0.0338 - val_accuracy: 0.9854 - val_loss: 0.1036\n",
      "Epoch 600/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9900 - loss: 0.0345 - val_accuracy: 0.9846 - val_loss: 0.1088\n",
      "Epoch 650/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9913 - loss: 0.0304 - val_accuracy: 0.9815 - val_loss: 0.1168\n",
      "Epoch 700/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9890 - loss: 0.0356 - val_accuracy: 0.9823 - val_loss: 0.1184\n",
      "Epoch 750/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9910 - loss: 0.0359 - val_accuracy: 0.9869 - val_loss: 0.1159\n",
      "Epoch 800/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9928 - loss: 0.0287 - val_accuracy: 0.9908 - val_loss: 0.1214\n",
      "Epoch 850/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9931 - loss: 0.0285 - val_accuracy: 0.9854 - val_loss: 0.1256\n",
      "Epoch 900/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9928 - loss: 0.0269 - val_accuracy: 0.9862 - val_loss: 0.1312\n",
      "Epoch 950/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9928 - loss: 0.0264 - val_accuracy: 0.9869 - val_loss: 0.1317\n",
      "Epoch 1000/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9936 - loss: 0.0255 - val_accuracy: 0.9869 - val_loss: 0.1369\n",
      "Epoch 1050/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9900 - loss: 0.0303 - val_accuracy: 0.9892 - val_loss: 0.1474\n",
      "Epoch 1100/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9931 - loss: 0.0243 - val_accuracy: 0.9908 - val_loss: 0.1523\n",
      "Epoch 1150/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9936 - loss: 0.0240 - val_accuracy: 0.9885 - val_loss: 0.1550\n",
      "Epoch 1200/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9926 - loss: 0.0235 - val_accuracy: 0.9908 - val_loss: 0.1559\n",
      "Epoch 1250/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9933 - loss: 0.0237 - val_accuracy: 0.9892 - val_loss: 0.1665\n",
      "Epoch 1300/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9928 - loss: 0.0219 - val_accuracy: 0.9892 - val_loss: 0.1709\n",
      "Epoch 1350/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9936 - loss: 0.0204 - val_accuracy: 0.9892 - val_loss: 0.1749\n",
      "Epoch 1400/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9926 - loss: 0.0248 - val_accuracy: 0.9892 - val_loss: 0.1728\n",
      "Epoch 1450/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9944 - loss: 0.0191 - val_accuracy: 0.9877 - val_loss: 0.1756\n",
      "Epoch 1500/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9918 - loss: 0.0224 - val_accuracy: 0.9885 - val_loss: 0.1855\n",
      "Epoch 1550/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9949 - loss: 0.0180 - val_accuracy: 0.9869 - val_loss: 0.1882\n",
      "Epoch 1600/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9928 - loss: 0.0237 - val_accuracy: 0.9838 - val_loss: 0.1823\n",
      "Epoch 1650/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9949 - loss: 0.0191 - val_accuracy: 0.9885 - val_loss: 0.1791\n",
      "Epoch 1700/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9938 - loss: 0.0188 - val_accuracy: 0.9815 - val_loss: 0.1970\n",
      "Epoch 1750/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9954 - loss: 0.0167 - val_accuracy: 0.9908 - val_loss: 0.1995\n",
      "Epoch 1800/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9959 - loss: 0.0171 - val_accuracy: 0.9823 - val_loss: 0.1988\n",
      "Epoch 1850/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9933 - loss: 0.0197 - val_accuracy: 0.9815 - val_loss: 0.2091\n",
      "Epoch 1900/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9936 - loss: 0.0180 - val_accuracy: 0.9823 - val_loss: 0.2233\n",
      "Epoch 1950/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9920 - loss: 0.0209 - val_accuracy: 0.9846 - val_loss: 0.2205\n",
      "Epoch 2000/2000\n",
      "10/10 ━━━━━━━━━━━━━━━━━━━━ accuracy: 0.9946 - loss: 0.0172 - val_accuracy: 0.9869 - val_loss: 0.2300\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import tensorflow as tf\n",
    "# 50번마다 한 번씩 출력하는 콜백 함수\n",
    "def custom_log(epoch, logs):\n",
    " if (epoch + 1) % 50 == 0:\n",
    "    num_batches = len(X_train) // 500\n",
    "    print(f\"Epoch {epoch+1}/2000\")\n",
    "    tf.print(f\"{num_batches}/{num_batches} ━━━━━━━━━━━━━━━━━━━━ \"\n",
    "              f\"accuracy: {logs['accuracy']:.4f} - loss: {logs['loss']:.4f} - \"\n",
    "              f\"val_accuracy: {logs['val_accuracy']:.4f} - val_loss: {logs['val_loss']:.4f}\")\n",
    "show_status = LambdaCallback(on_epoch_end=custom_log)\n",
    "\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=0, callbacks=show_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950731</td>\n",
       "      <td>0.129171</td>\n",
       "      <td>0.943846</td>\n",
       "      <td>0.161029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950475</td>\n",
       "      <td>0.128555</td>\n",
       "      <td>0.944615</td>\n",
       "      <td>0.161158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.950475</td>\n",
       "      <td>0.126125</td>\n",
       "      <td>0.943846</td>\n",
       "      <td>0.160449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.950475</td>\n",
       "      <td>0.124890</td>\n",
       "      <td>0.945385</td>\n",
       "      <td>0.154858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.952784</td>\n",
       "      <td>0.122867</td>\n",
       "      <td>0.945385</td>\n",
       "      <td>0.155897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.995381</td>\n",
       "      <td>0.016207</td>\n",
       "      <td>0.982308</td>\n",
       "      <td>0.230376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.994611</td>\n",
       "      <td>0.016294</td>\n",
       "      <td>0.986923</td>\n",
       "      <td>0.228783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.994355</td>\n",
       "      <td>0.016679</td>\n",
       "      <td>0.986154</td>\n",
       "      <td>0.222923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.995381</td>\n",
       "      <td>0.016365</td>\n",
       "      <td>0.988462</td>\n",
       "      <td>0.227401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.994611</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>0.986923</td>\n",
       "      <td>0.229999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy      loss  val_accuracy  val_loss\n",
       "0     0.950731  0.129171      0.943846  0.161029\n",
       "1     0.950475  0.128555      0.944615  0.161158\n",
       "2     0.950475  0.126125      0.943846  0.160449\n",
       "3     0.950475  0.124890      0.945385  0.154858\n",
       "4     0.952784  0.122867      0.945385  0.155897\n",
       "...        ...       ...           ...       ...\n",
       "1995  0.995381  0.016207      0.982308  0.230376\n",
       "1996  0.994611  0.016294      0.986923  0.228783\n",
       "1997  0.994355  0.016679      0.986154  0.222923\n",
       "1998  0.995381  0.016365      0.988462  0.227401\n",
       "1999  0.994611  0.017187      0.986923  0.229999\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_df=pd.DataFrame(history.history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y_vloss에 테스트셋(여기서는 검증셋)의 오차를 저장합니다.\n",
    "y_vloss=hist_df['val_loss']\n",
    "# y_loss에 학습셋의 오차를 저장합니다.\n",
    "y_loss=hist_df['loss']\n",
    "#x 값을 지정하고 테스트셋(검증셋)의 오차를 빨간색으로, 학습셋의 오차를 파란색으로 표시합니다.\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2, label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=2, label='Trainset_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">372</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m390\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m372\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">875</span> (3.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m875\u001b[0m (3.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('./datas/wine.csv', header=None)\n",
    "# 와인의 속성을 X로 와인의 분류를 y로 저장합니다.\n",
    "X = df.iloc[:,0:12]\n",
    "y = df.iloc[:,12]\n",
    "# 학습셋과 테스트셋으로 나눕니다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "# 모델 구조를 설정합니다.\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "# 모델을 컴파일합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2503 - loss: 11.3288 - val_accuracy: 0.2354 - val_loss: 7.8213\n",
      "Epoch 2/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2507 - loss: 6.3146 - val_accuracy: 0.2354 - val_loss: 3.4968\n",
      "Epoch 3/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2547 - loss: 3.0103 - val_accuracy: 0.2354 - val_loss: 2.0561\n",
      "Epoch 4/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2507 - loss: 1.7100 - val_accuracy: 0.2354 - val_loss: 1.0108\n",
      "Epoch 5/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2612 - loss: 0.8480 - val_accuracy: 0.9138 - val_loss: 0.5863\n",
      "Epoch 6/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9317 - loss: 0.5331 - val_accuracy: 0.9315 - val_loss: 0.4194\n",
      "Epoch 7/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9327 - loss: 0.3896 - val_accuracy: 0.9308 - val_loss: 0.3339\n",
      "Epoch 8/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9317 - loss: 0.3198 - val_accuracy: 0.9315 - val_loss: 0.2873\n",
      "Epoch 9/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9334 - loss: 0.2733 - val_accuracy: 0.9331 - val_loss: 0.2606\n",
      "Epoch 10/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9394 - loss: 0.2450 - val_accuracy: 0.9338 - val_loss: 0.2439\n",
      "Epoch 11/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9378 - loss: 0.2303 - val_accuracy: 0.9338 - val_loss: 0.2325\n",
      "Epoch 12/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9374 - loss: 0.2226 - val_accuracy: 0.9338 - val_loss: 0.2243\n",
      "Epoch 13/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9393 - loss: 0.2127 - val_accuracy: 0.9331 - val_loss: 0.2185\n",
      "Epoch 14/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9433 - loss: 0.2010 - val_accuracy: 0.9338 - val_loss: 0.2138\n",
      "Epoch 15/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9421 - loss: 0.1968 - val_accuracy: 0.9338 - val_loss: 0.2104\n",
      "Epoch 16/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9428 - loss: 0.1927 - val_accuracy: 0.9338 - val_loss: 0.2077\n",
      "Epoch 17/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9393 - loss: 0.1958 - val_accuracy: 0.9338 - val_loss: 0.2059\n",
      "Epoch 18/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9388 - loss: 0.1908 - val_accuracy: 0.9346 - val_loss: 0.2039\n",
      "Epoch 19/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9403 - loss: 0.1873 - val_accuracy: 0.9346 - val_loss: 0.2028\n",
      "Epoch 20/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9409 - loss: 0.1898 - val_accuracy: 0.9338 - val_loss: 0.2016\n",
      "Epoch 21/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9427 - loss: 0.1842 - val_accuracy: 0.9346 - val_loss: 0.2005\n",
      "Epoch 22/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9387 - loss: 0.1902 - val_accuracy: 0.9338 - val_loss: 0.1999\n",
      "Epoch 23/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9429 - loss: 0.1816 - val_accuracy: 0.9346 - val_loss: 0.1996\n",
      "Epoch 24/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9350 - loss: 0.1947 - val_accuracy: 0.9346 - val_loss: 0.1982\n",
      "Epoch 25/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.1969 - val_accuracy: 0.9346 - val_loss: 0.1982\n",
      "Epoch 26/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9404 - loss: 0.1832 - val_accuracy: 0.9338 - val_loss: 0.1974\n",
      "Epoch 27/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9451 - loss: 0.1758 - val_accuracy: 0.9338 - val_loss: 0.1971\n",
      "Epoch 28/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9429 - loss: 0.1750 - val_accuracy: 0.9346 - val_loss: 0.1963\n",
      "Epoch 29/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9407 - loss: 0.1887 - val_accuracy: 0.9346 - val_loss: 0.1960\n",
      "Epoch 30/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9404 - loss: 0.1888 - val_accuracy: 0.9346 - val_loss: 0.1963\n",
      "Epoch 31/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9439 - loss: 0.1746 - val_accuracy: 0.9346 - val_loss: 0.1963\n",
      "Epoch 32/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9402 - loss: 0.1782 - val_accuracy: 0.9346 - val_loss: 0.1967\n",
      "Epoch 33/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9428 - loss: 0.1730 - val_accuracy: 0.9346 - val_loss: 0.1962\n",
      "Epoch 34/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9365 - loss: 0.1852 - val_accuracy: 0.9346 - val_loss: 0.1941\n",
      "Epoch 35/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9478 - loss: 0.1679 - val_accuracy: 0.9338 - val_loss: 0.1940\n",
      "Epoch 36/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9403 - loss: 0.1853 - val_accuracy: 0.9346 - val_loss: 0.1928\n",
      "Epoch 37/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9406 - loss: 0.1796 - val_accuracy: 0.9354 - val_loss: 0.1919\n",
      "Epoch 38/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9492 - loss: 0.1647 - val_accuracy: 0.9369 - val_loss: 0.1904\n",
      "Epoch 39/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9416 - loss: 0.1759 - val_accuracy: 0.9369 - val_loss: 0.1893\n",
      "Epoch 40/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9417 - loss: 0.1780 - val_accuracy: 0.9354 - val_loss: 0.1894\n",
      "Epoch 41/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9408 - loss: 0.1765 - val_accuracy: 0.9362 - val_loss: 0.1884\n",
      "Epoch 42/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9411 - loss: 0.1807 - val_accuracy: 0.9354 - val_loss: 0.1915\n",
      "Epoch 43/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9423 - loss: 0.1738 - val_accuracy: 0.9377 - val_loss: 0.1885\n",
      "Epoch 44/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9451 - loss: 0.1676 - val_accuracy: 0.9362 - val_loss: 0.1892\n",
      "Epoch 45/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9461 - loss: 0.1657 - val_accuracy: 0.9377 - val_loss: 0.1861\n",
      "Epoch 46/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9443 - loss: 0.1744 - val_accuracy: 0.9377 - val_loss: 0.1855\n",
      "Epoch 47/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9435 - loss: 0.1726 - val_accuracy: 0.9392 - val_loss: 0.1834\n",
      "Epoch 48/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9461 - loss: 0.1653 - val_accuracy: 0.9392 - val_loss: 0.1823\n",
      "Epoch 49/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9460 - loss: 0.1615 - val_accuracy: 0.9408 - val_loss: 0.1813\n",
      "Epoch 50/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9423 - loss: 0.1668 - val_accuracy: 0.9408 - val_loss: 0.1815\n",
      "Epoch 51/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9473 - loss: 0.1588 - val_accuracy: 0.9423 - val_loss: 0.1760\n",
      "Epoch 52/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9441 - loss: 0.1698 - val_accuracy: 0.9415 - val_loss: 0.1731\n",
      "Epoch 53/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9500 - loss: 0.1558 - val_accuracy: 0.9423 - val_loss: 0.1722\n",
      "Epoch 54/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9481 - loss: 0.1518 - val_accuracy: 0.9423 - val_loss: 0.1690\n",
      "Epoch 55/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9478 - loss: 0.1494 - val_accuracy: 0.9415 - val_loss: 0.1697\n",
      "Epoch 56/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9449 - loss: 0.1549 - val_accuracy: 0.9423 - val_loss: 0.1673\n",
      "Epoch 57/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9456 - loss: 0.1521 - val_accuracy: 0.9415 - val_loss: 0.1684\n",
      "Epoch 58/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9452 - loss: 0.1518 - val_accuracy: 0.9423 - val_loss: 0.1632\n",
      "Epoch 59/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9534 - loss: 0.1418 - val_accuracy: 0.9438 - val_loss: 0.1621\n",
      "Epoch 60/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9534 - loss: 0.1376 - val_accuracy: 0.9438 - val_loss: 0.1602\n",
      "Epoch 61/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9489 - loss: 0.1423 - val_accuracy: 0.9431 - val_loss: 0.1615\n",
      "Epoch 62/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9502 - loss: 0.1407 - val_accuracy: 0.9438 - val_loss: 0.1593\n",
      "Epoch 63/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9484 - loss: 0.1401 - val_accuracy: 0.9446 - val_loss: 0.1567\n",
      "Epoch 64/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9471 - loss: 0.1405 - val_accuracy: 0.9454 - val_loss: 0.1542\n",
      "Epoch 65/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9510 - loss: 0.1387 - val_accuracy: 0.9446 - val_loss: 0.1549\n",
      "Epoch 66/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9501 - loss: 0.1333 - val_accuracy: 0.9446 - val_loss: 0.1516\n",
      "Epoch 67/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9516 - loss: 0.1372 - val_accuracy: 0.9469 - val_loss: 0.1513\n",
      "Epoch 68/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9539 - loss: 0.1290 - val_accuracy: 0.9446 - val_loss: 0.1508\n",
      "Epoch 69/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9522 - loss: 0.1339 - val_accuracy: 0.9454 - val_loss: 0.1466\n",
      "Epoch 70/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9524 - loss: 0.1307 - val_accuracy: 0.9446 - val_loss: 0.1466\n",
      "Epoch 71/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9545 - loss: 0.1252 - val_accuracy: 0.9469 - val_loss: 0.1431\n",
      "Epoch 72/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9579 - loss: 0.1259 - val_accuracy: 0.9462 - val_loss: 0.1402\n",
      "Epoch 73/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9558 - loss: 0.1180 - val_accuracy: 0.9462 - val_loss: 0.1395\n",
      "Epoch 74/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.1251 - val_accuracy: 0.9438 - val_loss: 0.1433\n",
      "Epoch 75/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9552 - loss: 0.1233 - val_accuracy: 0.9462 - val_loss: 0.1365\n",
      "Epoch 76/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9563 - loss: 0.1160 - val_accuracy: 0.9477 - val_loss: 0.1309\n",
      "Epoch 77/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9585 - loss: 0.1158 - val_accuracy: 0.9485 - val_loss: 0.1282\n",
      "Epoch 78/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9585 - loss: 0.1201 - val_accuracy: 0.9554 - val_loss: 0.1248\n",
      "Epoch 79/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9582 - loss: 0.1141 - val_accuracy: 0.9523 - val_loss: 0.1244\n",
      "Epoch 80/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9641 - loss: 0.1119 - val_accuracy: 0.9531 - val_loss: 0.1232\n",
      "Epoch 81/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9645 - loss: 0.1118 - val_accuracy: 0.9515 - val_loss: 0.1280\n",
      "Epoch 82/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9615 - loss: 0.1142 - val_accuracy: 0.9554 - val_loss: 0.1215\n",
      "Epoch 83/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9677 - loss: 0.1083 - val_accuracy: 0.9623 - val_loss: 0.1182\n",
      "Epoch 84/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9640 - loss: 0.1081 - val_accuracy: 0.9554 - val_loss: 0.1159\n",
      "Epoch 85/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9711 - loss: 0.0990 - val_accuracy: 0.9554 - val_loss: 0.1154\n",
      "Epoch 86/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9690 - loss: 0.1007 - val_accuracy: 0.9515 - val_loss: 0.1183\n",
      "Epoch 87/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9636 - loss: 0.1069 - val_accuracy: 0.9546 - val_loss: 0.1158\n",
      "Epoch 88/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9672 - loss: 0.0988 - val_accuracy: 0.9546 - val_loss: 0.1149\n",
      "Epoch 89/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9646 - loss: 0.1041 - val_accuracy: 0.9608 - val_loss: 0.1112\n",
      "Epoch 90/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9691 - loss: 0.0971 - val_accuracy: 0.9608 - val_loss: 0.1103\n",
      "Epoch 91/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9707 - loss: 0.0987 - val_accuracy: 0.9685 - val_loss: 0.1082\n",
      "Epoch 92/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9643 - loss: 0.0986 - val_accuracy: 0.9615 - val_loss: 0.1081\n",
      "Epoch 93/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9670 - loss: 0.1012 - val_accuracy: 0.9662 - val_loss: 0.1059\n",
      "Epoch 94/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9665 - loss: 0.0986 - val_accuracy: 0.9700 - val_loss: 0.1060\n",
      "Epoch 95/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9702 - loss: 0.0925 - val_accuracy: 0.9631 - val_loss: 0.1053\n",
      "Epoch 96/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9742 - loss: 0.0863 - val_accuracy: 0.9669 - val_loss: 0.1045\n",
      "Epoch 97/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9720 - loss: 0.0889 - val_accuracy: 0.9677 - val_loss: 0.1027\n",
      "Epoch 98/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9757 - loss: 0.0862 - val_accuracy: 0.9662 - val_loss: 0.1025\n",
      "Epoch 99/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9716 - loss: 0.0962 - val_accuracy: 0.9554 - val_loss: 0.1107\n",
      "Epoch 100/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9711 - loss: 0.0828 - val_accuracy: 0.9585 - val_loss: 0.1063\n",
      "Epoch 101/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9678 - loss: 0.0980 - val_accuracy: 0.9692 - val_loss: 0.1001\n",
      "Epoch 102/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9714 - loss: 0.0859 - val_accuracy: 0.9662 - val_loss: 0.0979\n",
      "Epoch 103/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9721 - loss: 0.0856 - val_accuracy: 0.9554 - val_loss: 0.1135\n",
      "Epoch 104/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9694 - loss: 0.0881 - val_accuracy: 0.9708 - val_loss: 0.0976\n",
      "Epoch 105/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9708 - loss: 0.0853 - val_accuracy: 0.9708 - val_loss: 0.1015\n",
      "Epoch 106/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9739 - loss: 0.0858 - val_accuracy: 0.9708 - val_loss: 0.0957\n",
      "Epoch 107/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9737 - loss: 0.0807 - val_accuracy: 0.9715 - val_loss: 0.1003\n",
      "Epoch 108/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9727 - loss: 0.0801 - val_accuracy: 0.9700 - val_loss: 0.0945\n",
      "Epoch 109/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9749 - loss: 0.0798 - val_accuracy: 0.9723 - val_loss: 0.0974\n",
      "Epoch 110/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9752 - loss: 0.0775 - val_accuracy: 0.9677 - val_loss: 0.0953\n",
      "Epoch 111/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9717 - loss: 0.0794 - val_accuracy: 0.9731 - val_loss: 0.0931\n",
      "Epoch 112/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9749 - loss: 0.0807 - val_accuracy: 0.9715 - val_loss: 0.0920\n",
      "Epoch 113/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0811 - val_accuracy: 0.9654 - val_loss: 0.0947\n",
      "Epoch 114/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9757 - loss: 0.0785 - val_accuracy: 0.9692 - val_loss: 0.0917\n",
      "Epoch 115/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.0805 - val_accuracy: 0.9715 - val_loss: 0.0908\n",
      "Epoch 116/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9771 - loss: 0.0771 - val_accuracy: 0.9723 - val_loss: 0.0897\n",
      "Epoch 117/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9780 - loss: 0.0747 - val_accuracy: 0.9731 - val_loss: 0.0894\n",
      "Epoch 118/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 0.0798 - val_accuracy: 0.9723 - val_loss: 0.0920\n",
      "Epoch 119/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9746 - loss: 0.0821 - val_accuracy: 0.9738 - val_loss: 0.0886\n",
      "Epoch 120/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9781 - loss: 0.0728 - val_accuracy: 0.9754 - val_loss: 0.0883\n",
      "Epoch 121/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9773 - loss: 0.0701 - val_accuracy: 0.9738 - val_loss: 0.0879\n",
      "Epoch 122/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9765 - loss: 0.0779 - val_accuracy: 0.9746 - val_loss: 0.0871\n",
      "Epoch 123/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0736 - val_accuracy: 0.9700 - val_loss: 0.0888\n",
      "Epoch 124/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9769 - loss: 0.0713 - val_accuracy: 0.9669 - val_loss: 0.0919\n",
      "Epoch 125/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9779 - loss: 0.0752 - val_accuracy: 0.9685 - val_loss: 0.0943\n",
      "Epoch 126/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9748 - loss: 0.0798 - val_accuracy: 0.9685 - val_loss: 0.0931\n",
      "Epoch 127/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9783 - loss: 0.0688 - val_accuracy: 0.9677 - val_loss: 0.0901\n",
      "Epoch 128/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9813 - loss: 0.0673 - val_accuracy: 0.9715 - val_loss: 0.0862\n",
      "Epoch 129/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9786 - loss: 0.0679 - val_accuracy: 0.9700 - val_loss: 0.0867\n",
      "Epoch 130/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9773 - loss: 0.0681 - val_accuracy: 0.9654 - val_loss: 0.0990\n",
      "Epoch 131/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.0807 - val_accuracy: 0.9685 - val_loss: 0.0944\n",
      "Epoch 132/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9750 - loss: 0.0759 - val_accuracy: 0.9685 - val_loss: 0.0912\n",
      "Epoch 133/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9777 - loss: 0.0689 - val_accuracy: 0.9677 - val_loss: 0.0952\n",
      "Epoch 134/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9798 - loss: 0.0708 - val_accuracy: 0.9769 - val_loss: 0.0827\n",
      "Epoch 135/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9803 - loss: 0.0600 - val_accuracy: 0.9769 - val_loss: 0.0827\n",
      "Epoch 136/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9806 - loss: 0.0674 - val_accuracy: 0.9769 - val_loss: 0.0841\n",
      "Epoch 137/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9813 - loss: 0.0636 - val_accuracy: 0.9785 - val_loss: 0.0821\n",
      "Epoch 138/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9806 - loss: 0.0702 - val_accuracy: 0.9792 - val_loss: 0.0813\n",
      "Epoch 139/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9822 - loss: 0.0638 - val_accuracy: 0.9777 - val_loss: 0.0824\n",
      "Epoch 140/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0606 - val_accuracy: 0.9785 - val_loss: 0.0802\n",
      "Epoch 141/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9795 - loss: 0.0637 - val_accuracy: 0.9754 - val_loss: 0.0812\n",
      "Epoch 142/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9811 - loss: 0.0669 - val_accuracy: 0.9677 - val_loss: 0.0855\n",
      "Epoch 143/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.0683 - val_accuracy: 0.9715 - val_loss: 0.0828\n",
      "Epoch 144/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9812 - loss: 0.0655 - val_accuracy: 0.9738 - val_loss: 0.0811\n",
      "Epoch 145/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9834 - loss: 0.0600 - val_accuracy: 0.9762 - val_loss: 0.0797\n",
      "Epoch 146/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9816 - loss: 0.0641 - val_accuracy: 0.9769 - val_loss: 0.0791\n",
      "Epoch 147/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0537 - val_accuracy: 0.9769 - val_loss: 0.0804\n",
      "Epoch 148/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.0629 - val_accuracy: 0.9785 - val_loss: 0.0785\n",
      "Epoch 149/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9783 - loss: 0.0685 - val_accuracy: 0.9769 - val_loss: 0.0776\n",
      "Epoch 150/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9796 - loss: 0.0674 - val_accuracy: 0.9769 - val_loss: 0.0776\n",
      "Epoch 151/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9784 - loss: 0.0656 - val_accuracy: 0.9685 - val_loss: 0.0861\n",
      "Epoch 152/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9795 - loss: 0.0629 - val_accuracy: 0.9646 - val_loss: 0.0936\n",
      "Epoch 153/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9780 - loss: 0.0669 - val_accuracy: 0.9677 - val_loss: 0.0896\n",
      "Epoch 154/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 0.0582 - val_accuracy: 0.9746 - val_loss: 0.0786\n",
      "Epoch 155/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9820 - loss: 0.0611 - val_accuracy: 0.9762 - val_loss: 0.0771\n",
      "Epoch 156/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9794 - loss: 0.0659 - val_accuracy: 0.9769 - val_loss: 0.0803\n",
      "Epoch 157/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9804 - loss: 0.0587 - val_accuracy: 0.9769 - val_loss: 0.0766\n",
      "Epoch 158/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0526 - val_accuracy: 0.9785 - val_loss: 0.0772\n",
      "Epoch 159/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9825 - loss: 0.0539 - val_accuracy: 0.9777 - val_loss: 0.0765\n",
      "Epoch 160/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0594 - val_accuracy: 0.9762 - val_loss: 0.0787\n",
      "Epoch 161/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9826 - loss: 0.0591 - val_accuracy: 0.9777 - val_loss: 0.0777\n",
      "Epoch 162/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9849 - loss: 0.0541 - val_accuracy: 0.9777 - val_loss: 0.0759\n",
      "Epoch 163/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9820 - loss: 0.0593 - val_accuracy: 0.9762 - val_loss: 0.0752\n",
      "Epoch 164/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9820 - loss: 0.0598 - val_accuracy: 0.9777 - val_loss: 0.0757\n",
      "Epoch 165/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0545 - val_accuracy: 0.9777 - val_loss: 0.0750\n",
      "Epoch 166/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9850 - loss: 0.0564 - val_accuracy: 0.9792 - val_loss: 0.0760\n",
      "Epoch 167/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9833 - loss: 0.0627 - val_accuracy: 0.9792 - val_loss: 0.0787\n",
      "Epoch 168/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9793 - loss: 0.0670 - val_accuracy: 0.9800 - val_loss: 0.0767\n",
      "Epoch 169/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9821 - loss: 0.0593 - val_accuracy: 0.9800 - val_loss: 0.0758\n",
      "Epoch 170/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0629 - val_accuracy: 0.9769 - val_loss: 0.0743\n",
      "Epoch 171/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.0566 - val_accuracy: 0.9785 - val_loss: 0.0735\n",
      "Epoch 172/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9817 - loss: 0.0591 - val_accuracy: 0.9777 - val_loss: 0.0735\n",
      "Epoch 173/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.0588 - val_accuracy: 0.9800 - val_loss: 0.0757\n",
      "Epoch 174/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9842 - loss: 0.0562 - val_accuracy: 0.9785 - val_loss: 0.0735\n",
      "Epoch 175/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9828 - loss: 0.0540 - val_accuracy: 0.9792 - val_loss: 0.0734\n",
      "Epoch 176/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0539 - val_accuracy: 0.9792 - val_loss: 0.0731\n",
      "Epoch 177/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0503 - val_accuracy: 0.9785 - val_loss: 0.0738\n",
      "Epoch 178/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0493 - val_accuracy: 0.9800 - val_loss: 0.0737\n",
      "Epoch 179/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0506 - val_accuracy: 0.9808 - val_loss: 0.0738\n",
      "Epoch 180/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9838 - loss: 0.0559 - val_accuracy: 0.9800 - val_loss: 0.0739\n",
      "Epoch 181/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9843 - loss: 0.0526 - val_accuracy: 0.9800 - val_loss: 0.0730\n",
      "Epoch 182/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9820 - loss: 0.0561 - val_accuracy: 0.9800 - val_loss: 0.0725\n",
      "Epoch 183/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9819 - loss: 0.0594 - val_accuracy: 0.9792 - val_loss: 0.0721\n",
      "Epoch 184/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9846 - loss: 0.0524 - val_accuracy: 0.9792 - val_loss: 0.0728\n",
      "Epoch 185/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0527 - val_accuracy: 0.9800 - val_loss: 0.0734\n",
      "Epoch 186/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9831 - loss: 0.0549 - val_accuracy: 0.9792 - val_loss: 0.0725\n",
      "Epoch 187/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9838 - loss: 0.0538 - val_accuracy: 0.9808 - val_loss: 0.0741\n",
      "Epoch 188/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0498 - val_accuracy: 0.9792 - val_loss: 0.0767\n",
      "Epoch 189/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9828 - loss: 0.0544 - val_accuracy: 0.9785 - val_loss: 0.0800\n",
      "Epoch 190/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9803 - loss: 0.0669 - val_accuracy: 0.9754 - val_loss: 0.0765\n",
      "Epoch 191/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9799 - loss: 0.0588 - val_accuracy: 0.9700 - val_loss: 0.0868\n",
      "Epoch 192/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9808 - loss: 0.0663 - val_accuracy: 0.9700 - val_loss: 0.0829\n",
      "Epoch 193/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0527 - val_accuracy: 0.9792 - val_loss: 0.0747\n",
      "Epoch 194/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0561 - val_accuracy: 0.9715 - val_loss: 0.0811\n",
      "Epoch 195/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0574 - val_accuracy: 0.9800 - val_loss: 0.0726\n",
      "Epoch 196/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9852 - loss: 0.0480 - val_accuracy: 0.9808 - val_loss: 0.0714\n",
      "Epoch 197/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9862 - loss: 0.0508 - val_accuracy: 0.9808 - val_loss: 0.0715\n",
      "Epoch 198/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9860 - loss: 0.0480 - val_accuracy: 0.9792 - val_loss: 0.0773\n",
      "Epoch 199/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9791 - loss: 0.0655 - val_accuracy: 0.9823 - val_loss: 0.0713\n",
      "Epoch 200/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 0.0453 - val_accuracy: 0.9808 - val_loss: 0.0718\n",
      "Epoch 201/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9845 - loss: 0.0531 - val_accuracy: 0.9808 - val_loss: 0.0711\n",
      "Epoch 202/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9866 - loss: 0.0475 - val_accuracy: 0.9785 - val_loss: 0.0737\n",
      "Epoch 203/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9860 - loss: 0.0480 - val_accuracy: 0.9815 - val_loss: 0.0706\n",
      "Epoch 204/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9820 - loss: 0.0564 - val_accuracy: 0.9800 - val_loss: 0.0708\n",
      "Epoch 205/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9820 - loss: 0.0565 - val_accuracy: 0.9785 - val_loss: 0.0725\n",
      "Epoch 206/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9867 - loss: 0.0504 - val_accuracy: 0.9808 - val_loss: 0.0703\n",
      "Epoch 207/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.0481 - val_accuracy: 0.9815 - val_loss: 0.0697\n",
      "Epoch 208/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9810 - loss: 0.0551 - val_accuracy: 0.9815 - val_loss: 0.0700\n",
      "Epoch 209/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9838 - loss: 0.0559 - val_accuracy: 0.9823 - val_loss: 0.0700\n",
      "Epoch 210/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9832 - loss: 0.0581 - val_accuracy: 0.9823 - val_loss: 0.0702\n",
      "Epoch 211/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9828 - loss: 0.0505 - val_accuracy: 0.9823 - val_loss: 0.0708\n",
      "Epoch 212/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9841 - loss: 0.0525 - val_accuracy: 0.9823 - val_loss: 0.0710\n",
      "Epoch 213/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0525 - val_accuracy: 0.9831 - val_loss: 0.0704\n",
      "Epoch 214/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9858 - loss: 0.0521 - val_accuracy: 0.9815 - val_loss: 0.0695\n",
      "Epoch 215/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0488 - val_accuracy: 0.9762 - val_loss: 0.0750\n",
      "Epoch 216/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0479 - val_accuracy: 0.9815 - val_loss: 0.0701\n",
      "Epoch 217/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9832 - loss: 0.0550 - val_accuracy: 0.9785 - val_loss: 0.0714\n",
      "Epoch 218/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.0530 - val_accuracy: 0.9800 - val_loss: 0.0706\n",
      "Epoch 219/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9838 - loss: 0.0552 - val_accuracy: 0.9815 - val_loss: 0.0694\n",
      "Epoch 220/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9848 - loss: 0.0544 - val_accuracy: 0.9815 - val_loss: 0.0692\n",
      "Epoch 221/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.0531 - val_accuracy: 0.9808 - val_loss: 0.0698\n",
      "Epoch 222/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0583 - val_accuracy: 0.9785 - val_loss: 0.0717\n",
      "Epoch 223/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9849 - loss: 0.0545 - val_accuracy: 0.9754 - val_loss: 0.0750\n",
      "Epoch 224/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0605 - val_accuracy: 0.9785 - val_loss: 0.0716\n",
      "Epoch 225/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9862 - loss: 0.0469 - val_accuracy: 0.9815 - val_loss: 0.0688\n",
      "Epoch 226/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9877 - loss: 0.0426 - val_accuracy: 0.9823 - val_loss: 0.0685\n",
      "Epoch 227/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0462 - val_accuracy: 0.9777 - val_loss: 0.0705\n",
      "Epoch 228/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0525 - val_accuracy: 0.9808 - val_loss: 0.0697\n",
      "Epoch 229/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9824 - loss: 0.0571 - val_accuracy: 0.9700 - val_loss: 0.0842\n",
      "Epoch 230/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9806 - loss: 0.0610 - val_accuracy: 0.9769 - val_loss: 0.0725\n",
      "Epoch 231/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0507 - val_accuracy: 0.9808 - val_loss: 0.0685\n",
      "Epoch 232/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9852 - loss: 0.0484 - val_accuracy: 0.9769 - val_loss: 0.0717\n",
      "Epoch 233/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9848 - loss: 0.0500 - val_accuracy: 0.9808 - val_loss: 0.0697\n",
      "Epoch 234/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9857 - loss: 0.0464 - val_accuracy: 0.9800 - val_loss: 0.0697\n",
      "Epoch 235/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9839 - loss: 0.0496 - val_accuracy: 0.9754 - val_loss: 0.0758\n",
      "Epoch 236/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0578 - val_accuracy: 0.9762 - val_loss: 0.0739\n",
      "Epoch 237/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9858 - loss: 0.0452 - val_accuracy: 0.9808 - val_loss: 0.0695\n",
      "Epoch 238/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9860 - loss: 0.0435 - val_accuracy: 0.9815 - val_loss: 0.0688\n",
      "Epoch 239/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9857 - loss: 0.0463 - val_accuracy: 0.9838 - val_loss: 0.0690\n",
      "Epoch 240/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0460 - val_accuracy: 0.9823 - val_loss: 0.0684\n",
      "Epoch 241/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9834 - loss: 0.0511 - val_accuracy: 0.9846 - val_loss: 0.0680\n",
      "Epoch 242/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9860 - loss: 0.0463 - val_accuracy: 0.9823 - val_loss: 0.0710\n",
      "Epoch 243/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9857 - loss: 0.0506 - val_accuracy: 0.9846 - val_loss: 0.0679\n",
      "Epoch 244/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9834 - loss: 0.0465 - val_accuracy: 0.9846 - val_loss: 0.0692\n",
      "Epoch 245/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9835 - loss: 0.0512 - val_accuracy: 0.9800 - val_loss: 0.0685\n",
      "Epoch 246/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0523 - val_accuracy: 0.9854 - val_loss: 0.0683\n",
      "Epoch 247/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0545 - val_accuracy: 0.9800 - val_loss: 0.0738\n",
      "Epoch 248/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9838 - loss: 0.0491 - val_accuracy: 0.9823 - val_loss: 0.0713\n",
      "Epoch 249/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0458 - val_accuracy: 0.9854 - val_loss: 0.0675\n",
      "Epoch 250/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9868 - loss: 0.0412 - val_accuracy: 0.9808 - val_loss: 0.0682\n",
      "Epoch 251/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9862 - loss: 0.0450 - val_accuracy: 0.9808 - val_loss: 0.0687\n",
      "Epoch 252/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9843 - loss: 0.0474 - val_accuracy: 0.9831 - val_loss: 0.0678\n",
      "Epoch 253/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9876 - loss: 0.0419 - val_accuracy: 0.9823 - val_loss: 0.0708\n",
      "Epoch 254/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9867 - loss: 0.0413 - val_accuracy: 0.9808 - val_loss: 0.0678\n",
      "Epoch 255/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.0421 - val_accuracy: 0.9823 - val_loss: 0.0669\n",
      "Epoch 256/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9853 - loss: 0.0513 - val_accuracy: 0.9846 - val_loss: 0.0675\n",
      "Epoch 257/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9846 - loss: 0.0462 - val_accuracy: 0.9808 - val_loss: 0.0682\n",
      "Epoch 258/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9867 - loss: 0.0421 - val_accuracy: 0.9831 - val_loss: 0.0673\n",
      "Epoch 259/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9837 - loss: 0.0490 - val_accuracy: 0.9808 - val_loss: 0.0674\n",
      "Epoch 260/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9835 - loss: 0.0498 - val_accuracy: 0.9846 - val_loss: 0.0672\n",
      "Epoch 261/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.0455 - val_accuracy: 0.9838 - val_loss: 0.0699\n",
      "Epoch 262/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9818 - loss: 0.0524 - val_accuracy: 0.9838 - val_loss: 0.0672\n",
      "Epoch 263/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9851 - loss: 0.0440 - val_accuracy: 0.9823 - val_loss: 0.0669\n",
      "Epoch 264/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9837 - loss: 0.0490 - val_accuracy: 0.9815 - val_loss: 0.0677\n",
      "Epoch 265/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.0454 - val_accuracy: 0.9846 - val_loss: 0.0672\n",
      "Epoch 266/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9853 - loss: 0.0411 - val_accuracy: 0.9831 - val_loss: 0.0696\n",
      "Epoch 267/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9862 - loss: 0.0470 - val_accuracy: 0.9831 - val_loss: 0.0668\n",
      "Epoch 268/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9844 - loss: 0.0496 - val_accuracy: 0.9831 - val_loss: 0.0669\n",
      "Epoch 269/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9829 - loss: 0.0497 - val_accuracy: 0.9808 - val_loss: 0.0671\n",
      "Epoch 270/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0463 - val_accuracy: 0.9762 - val_loss: 0.0726\n",
      "Epoch 271/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0490 - val_accuracy: 0.9808 - val_loss: 0.0671\n",
      "Epoch 272/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9850 - loss: 0.0462 - val_accuracy: 0.9823 - val_loss: 0.0662\n",
      "Epoch 273/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0392 - val_accuracy: 0.9815 - val_loss: 0.0704\n",
      "Epoch 274/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9838 - loss: 0.0490 - val_accuracy: 0.9800 - val_loss: 0.0744\n",
      "Epoch 275/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9847 - loss: 0.0437 - val_accuracy: 0.9777 - val_loss: 0.0794\n",
      "Epoch 276/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9836 - loss: 0.0489 - val_accuracy: 0.9846 - val_loss: 0.0676\n",
      "Epoch 277/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9861 - loss: 0.0412 - val_accuracy: 0.9808 - val_loss: 0.0678\n",
      "Epoch 278/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9856 - loss: 0.0459 - val_accuracy: 0.9831 - val_loss: 0.0689\n",
      "Epoch 279/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9835 - loss: 0.0470 - val_accuracy: 0.9846 - val_loss: 0.0675\n",
      "Epoch 280/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9875 - loss: 0.0436 - val_accuracy: 0.9792 - val_loss: 0.0761\n",
      "Epoch 281/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0533 - val_accuracy: 0.9838 - val_loss: 0.0691\n",
      "Epoch 282/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9851 - loss: 0.0475 - val_accuracy: 0.9831 - val_loss: 0.0668\n",
      "Epoch 283/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9859 - loss: 0.0428 - val_accuracy: 0.9785 - val_loss: 0.0694\n",
      "Epoch 284/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0530 - val_accuracy: 0.9762 - val_loss: 0.0734\n",
      "Epoch 285/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9827 - loss: 0.0511 - val_accuracy: 0.9746 - val_loss: 0.0765\n",
      "Epoch 286/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0513 - val_accuracy: 0.9769 - val_loss: 0.0714\n",
      "Epoch 287/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9840 - loss: 0.0484 - val_accuracy: 0.9854 - val_loss: 0.0670\n",
      "Epoch 288/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0399 - val_accuracy: 0.9846 - val_loss: 0.0683\n",
      "Epoch 289/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9839 - loss: 0.0469 - val_accuracy: 0.9838 - val_loss: 0.0672\n",
      "Epoch 290/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9857 - loss: 0.0420 - val_accuracy: 0.9854 - val_loss: 0.0669\n",
      "Epoch 291/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9858 - loss: 0.0433 - val_accuracy: 0.9838 - val_loss: 0.0668\n",
      "Epoch 292/2000\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9868 - loss: 0.0427 - val_accuracy: 0.9823 - val_loss: 0.0693\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
    "# 최적화 모델이 저장될 폴더와 모델의 이름을 정합니다.\n",
    "modelpath=\"./datas/model/bestmodel.keras\"\n",
    "# 최적화 모델을 업데이트하고 저장합니다.\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "# 모델을 실행합니다.\n",
    "history=model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split= 0.25, verbose = 1,\n",
    "                  callbacks = [early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9794 - loss: 0.0529 \n",
      "Test accuracy: 0.9815384745597839\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
